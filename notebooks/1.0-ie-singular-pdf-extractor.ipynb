{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "\n",
    "import os\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.path.dirname(os.getcwd())\n",
    "DATA_DIR = os.path.join(PROJECT_DIR, 'data')\n",
    "RAW_DIR = os.path.join(DATA_DIR, 'raw')\n",
    "TEXT_DIR = os.path.join(DATA_DIR, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"nous-hermes2\")\n",
    "# llm = Ollama(model=\"llama3\", format='json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'pdf': [],\n",
    "    'md': [],\n",
    "    'txt': [],\n",
    "    'json': []\n",
    "}\n",
    "\n",
    "for file in os.listdir(RAW_DIR):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        files['pdf'].append(os.path.join(RAW_DIR, file))\n",
    "\n",
    "    if file.endswith(\".md\"):\n",
    "        files['md'].append(os.path.join(RAW_DIR, file))\n",
    "\n",
    "    if file.endswith(\".txt\"):\n",
    "        files['txt'].append(os.path.join(RAW_DIR, file))\n",
    "\n",
    "    if file.endswith(\".json\"):\n",
    "        files['json'].append(os.path.join(RAW_DIR, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader, PyPDFLoader\n",
    "from typing import List\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF --> Markdown --> Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf4llm\n",
    "\n",
    "md_text = pymupdf4llm.to_markdown(files['pdf'][0], pages=None)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1024, \n",
    "    chunk_overlap=256\n",
    ")\n",
    "doc_splits = text_splitter.create_documents([md_text])\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"nous-hermes2\")\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore_md = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "retriever_md = vectorstore_md.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF --> Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyMuPDFLoader(files['pdf'][0])\n",
    "doc = loader.load()\n",
    "# docs_list = [page for doc in docs for page in doc]\n",
    "doc_list = [item for item in doc]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1024, chunk_overlap=256\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(doc_list)\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"nous-hermes2\")\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore_pdf = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "retriever_pdf = vectorstore_pdf.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your desired data structure.\n",
    "class ExInfo(BaseModel):\n",
    "    name: str = Field(description=\"research paper title, usually should be in the first page.\")\n",
    "    authors: str = Field(description=\"research paper authors, usually should be in the first page.\")\n",
    "    date: int = Field(description=\"research paper publication date in year-month format. look for the keyword 'published'\")\n",
    "    summary_abstract: str = Field(description=\"research paper summary abstract, usually should be in the first page.\")\n",
    "    limitation: str = Field(description=\"research paper limitation, usually should be at the end of the article.\")\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "paper_query = f\"Extract the information from the research paper\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=ExInfo)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    <|begin_of_text|>\n",
    "        <|start_header_id|>\n",
    "            system\n",
    "        <|end_header_id|> \n",
    "    You are an research assistant for extracting information from pdf file. \n",
    "    Use the following pieces of retrieved context to answer the question.\n",
    "    Output should be in json.\n",
    "    <|eot_id|>\n",
    "\n",
    "    <|start_header_id|>user<|end_header_id|>\n",
    "    {question}\n",
    "\n",
    "    Here are the pdf reference:\n",
    "    \\n ------- \\n\n",
    "    {document}\n",
    "    \\n ------- \\n\n",
    "\n",
    "    Follow this output format:\n",
    "    \\n ------- \\n\n",
    "    \\n{format_instructions}\\n\n",
    "    \\n ------- \\n\n",
    "    <|eot_id|>\n",
    "    \n",
    "    <|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM + PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'name': 'Fish Behavior Analysis in an Aquaculture Environment by Using Computer Vision Techniques',\n",
       "  'authors': 'Zhang, Qi; Zhang, Wei; Li, Wen; et al.',\n",
       "  'date': 20200814,\n",
       "  'summary_abstract': 'This paper proposes a method for fish behavior analysis in an aquaculture environment by using computer vision techniques. Firstly, the video is recorded by the underwater camera in the fish tank, which is placed at the center of the tank and faces downward. The camera has a resolution of 1920 Ã— 1080 pixels with a frame rate of 30 fps. Three experiments are carried out to analyze the behavior of the fish in the aquaculture environment. In the first experiment, 50 crucian carp are placed into the tank. The ammonia concentration is maintained at around 0.25 mg/L for 10 h. In the second experiment, 40 common carp are placed into the tank, and the ammonia concentration is increased to 8 mg/L in the first hour, then decreased to 3 mg/L in the next hour, and finally maintained at around 2.5 mg/L for another 7 h. In the third experiment, 50 crucian carp are placed into the tank, and the ammonia concentration is increased to 10 mg/L in the first hour and maintained at this level for the next 9 h. The video records the behavior of the fish under different environmental conditions, such as different light intensities and water temperatures.',\n",
       "  'limitation': 'The main limitation of this study is that it only focuses on the behavior of crucian carp and common carp in aquaculture environments. Further research should be conducted to explore the behavior of other species of fish under similar environmental conditions.'},\n",
       " 'required': ['name', 'authors', 'date', 'summary_abstract', 'limitation']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = retriever_pdf.invoke(paper_query)\n",
    "chain.invoke({\n",
    "    \"question\": paper_query,\n",
    "    \"document\": docs  \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM + Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Fish Behavior Under Diverse Environmental Conditions: A Study of Betta Fish',\n",
       " 'authors': 'Shi, Yi; Zhang, Xin; Li, Qian; Zhou, Jun; Tao, Feng',\n",
       " 'date': 202008,\n",
       " 'summary_abstract': \"In order to study the behavior of betta fish under different environmental conditions, an experimental device is designed to observe their behavior in real-time. The device includes a high-speed camera and a control system with sensors to monitor temperature, pH, dissolved oxygen (DO), and ammonia concentration. The fish's behavior is analyzed by image processing methods based on machine learning algorithms. The results show that betta fish can adapt to different environmental conditions, but under abnormal conditions such as high ammonia concentration, their behavior becomes more chaotic.\",\n",
       " 'limitation': 'The study has some limitations, including the small sample size of the fish (10 individuals), and the fact that the experiments were conducted in a laboratory setting rather than in natural environments. Further research is needed to validate these results in other conditions.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = retriever_md.invoke(paper_query)\n",
    "chain.invoke({\n",
    "    \"question\": paper_query,\n",
    "    \"document\": docs  \n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crew_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
