{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.path.dirname(os.getcwd())\n",
    "DATA_DIR = os.path.join(PROJECT_DIR, 'data')\n",
    "RAW_DIR = os.path.join(DATA_DIR, 'raw')\n",
    "TEXT_DIR = os.path.join(DATA_DIR, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"nous-hermes2\")\n",
    "# llm = Ollama(model=\"llama3\", format='json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'pdf': [],\n",
    "    'md': [],\n",
    "    'txt': [],\n",
    "    'json': []\n",
    "}\n",
    "\n",
    "for file in os.listdir(RAW_DIR):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        files['pdf'].append(os.path.join(RAW_DIR, file))\n",
    "\n",
    "    if file.endswith(\".md\"):\n",
    "        files['md'].append(os.path.join(RAW_DIR, file))\n",
    "\n",
    "    if file.endswith(\".txt\"):\n",
    "        files['txt'].append(os.path.join(RAW_DIR, file))\n",
    "\n",
    "    if file.endswith(\".json\"):\n",
    "        files['json'].append(os.path.join(RAW_DIR, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader, PyPDFLoader\n",
    "from typing import List\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyMuPDFLoader(files['pdf'][0])\n",
    "doc = loader.load()\n",
    "# docs_list = [page for doc in docs for page in doc]\n",
    "doc_list = [item for item in doc]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(doc_list)\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"nous-hermes2\")\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Fish Behavior Detection Using Convolutional Neural Networks',\n",
       " 'authors': 'Rui-Jie Yuan, Zhi-Yu Duan, Jia-Xin Lin and Peng-Song Gao',\n",
       " 'date': 20200814,\n",
       " 'summary_abstract': 'This paper proposes a method for fish behavior detection based on convolutional neural networks. The method is composed of two parts: feature extraction and behavior recognition. The feature extraction part uses the visual geometry group (VGG) network to extract features from input images. Behavior recognition is achieved by using an SVM classifier with the extracted features as inputs.',\n",
       " 'limitation': 'One limitation of our method is that it requires large amounts of labeled training data for behavior recognition. Additionally, the computation time and storage space requirements for the VGG network are relatively high.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your desired data structure.\n",
    "class ExInfo(BaseModel):\n",
    "    name: str = Field(description=\"research paper title, usually should be in the first page.\")\n",
    "    authors: str = Field(description=\"research paper authors, usually should be in the first page.\")\n",
    "    date: int = Field(description=\"research paper publication date in year-month format. look for the keyword 'published'\")\n",
    "    summary_abstract: str = Field(description=\"research paper summary abstract, usually should be in the first page.\")\n",
    "    limitation: str = Field(description=\"research paper limitation, usually should be at the end of the article.\")\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "paper_query = f\"Extract the information from the research paper\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=ExInfo)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    <|begin_of_text|>\n",
    "        <|start_header_id|>\n",
    "            system\n",
    "        <|end_header_id|> \n",
    "    You are an research assistant for extracting information from pdf file. \n",
    "    Use the following pieces of retrieved context to answer the question.\n",
    "    Output should be in json.\n",
    "    <|eot_id|>\n",
    "\n",
    "    <|start_header_id|>user<|end_header_id|>\n",
    "    {question}\n",
    "\n",
    "    Here are the pdf reference:\n",
    "    \\n ------- \\n\n",
    "    {document}\n",
    "    \\n ------- \\n\n",
    "\n",
    "    Follow this output format:\n",
    "    \\n ------- \\n\n",
    "    \\n{format_instructions}\\n\n",
    "    \\n ------- \\n\n",
    "    <|eot_id|>\n",
    "    \n",
    "    <|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "docs = retriever.invoke(paper_query)\n",
    "chain.invoke({\n",
    "    \"question\": paper_query,\n",
    "    \"document\": docs  \n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crew_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
